{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Image manipulation.\n",
    "from PIL import Image\n",
    "from scipy.ndimage.filters import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import inception5h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inception5h.maybe_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = inception5h.Inception5h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(model.layer_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "inception/5h/tensorflow_inception_graph.pb; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1eb07620e2eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprintTensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inception/5h/tensorflow_inception_graph.pb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1eb07620e2eb>\u001b[0m in \u001b[0;36mprintTensors\u001b[0;34m(pb_file)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpb_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# import graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    123\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         self._read_buf = pywrap_tensorflow.CreateBufferedInputStream(\n\u001b[0;32m---> 85\u001b[0;31m             compat.as_bytes(self.__name), 1024 * 512, status)\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: inception/5h/tensorflow_inception_graph.pb; No such file or directory"
     ]
    }
   ],
   "source": [
    "# to know the different layers in the inception 5h model\n",
    "import tensorflow as tf\n",
    "\n",
    "def printTensors(pb_file):\n",
    "\n",
    "    # read pb into graph_def\n",
    "    with tf.gfile.GFile(pb_file, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # import graph_def\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    # print operations\n",
    "    for op in graph.get_operations():\n",
    "        print(op.name)\n",
    "\n",
    "\n",
    "printTensors(\"inception/5h/tensorflow_inception_graph.pb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load the image using PIL\n",
    "def load_image(filename):\n",
    "    try:\n",
    "        original = Image.open(filename)\n",
    "        print(\"the size of the image is :\")\n",
    "        print(original.format,original.size)\n",
    "    except:\n",
    "        print (\"Unable to load image\")\n",
    "\n",
    "    return np.float32(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image, filename):\n",
    "    # Ensure the pixel-values are between 0 and 255.\n",
    "    image = np.clip(image, 0.0, 255.0)\n",
    "    \n",
    "    # Convert to bytes.\n",
    "    image = image.astype(np.uint8)\n",
    "    \n",
    "    # Write the image-file in jpeg-format.\n",
    "    with open(filename, 'wb') as file:\n",
    "        Image.fromarray(image).save(file, 'jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    # Assume the pixel-values are scaled between 0 and 255.\n",
    "    \n",
    "    if False:\n",
    "        # Convert the pixel-values to the range between 0.0 and 1.0\n",
    "        image = np.clip(image/255.0, 0.0, 1.0)\n",
    "        \n",
    "        # Plot using matplotlib.\n",
    "        plt.imshow(image, interpolation='lanczos')\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Ensure the pixel-values are between 0 and 255.\n",
    "        image = np.clip(image, 0.0, 255.0)\n",
    "        \n",
    "        # Convert pixels to bytes.\n",
    "        image = image.astype(np.uint8)\n",
    "\n",
    "        # Convert to a PIL-image and display it.\n",
    "        display(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(x):\n",
    "    # Get the min and max values for all pixels in the input.\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "\n",
    "    # Normalize so all values are between 0.0 and 1.0\n",
    "    x_norm = (x - x_min) / (x_max - x_min)\n",
    "    \n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gradient(gradient):\n",
    "    # Normalize the gradient so it is between 0.0 and 1.0\n",
    "    gradient_normalized = normalize_image(gradient)\n",
    "    \n",
    "    # Plot the normalized gradient.\n",
    "    plt.imshow(gradient_normalized, interpolation='bilinear')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, size=None, factor=None):\n",
    "    # If a rescaling-factor is provided then use it.\n",
    "    if factor is not None:\n",
    "        # Scale the numpy array's shape for height and width.\n",
    "        size = np.array(image.shape[0:2]) * factor\n",
    "        \n",
    "        # The size is floating-point because it was scaled.\n",
    "        # PIL requires the size to be integers.\n",
    "        size = size.astype(int)\n",
    "    else:\n",
    "        # Ensure the size has length 2.\n",
    "        size = size[0:2]\n",
    "    \n",
    "    # The height and width is reversed in numpy vs. PIL.\n",
    "    size = tuple(reversed(size))\n",
    "\n",
    "    # Ensure the pixel-values are between 0 and 255.\n",
    "    img = np.clip(image, 0.0, 255.0)\n",
    "    \n",
    "    # Convert the pixels to 8-bit bytes.\n",
    "    img = img.astype(np.uint8)\n",
    "    \n",
    "    # Create PIL-object from numpy array.\n",
    "    img = Image.fromarray(img)\n",
    "    \n",
    "    # Resize the image.\n",
    "    img_resized = img.resize(size, Image.LANCZOS)\n",
    "    \n",
    "    # Convert 8-bit pixel values back to floating-point.\n",
    "    img_resized = np.float32(img_resized)\n",
    "\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Dream Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_size(num_pixels, tile_size=400):\n",
    "    \"\"\"\n",
    "    num_pixels is the number of pixels in a dimension of the image.\n",
    "    tile_size is the desired tile-size.\n",
    "    \"\"\"\n",
    "\n",
    "    # How many times can we repeat a tile of the desired size.\n",
    "    num_tiles = int(round(num_pixels / tile_size))\n",
    "    \n",
    "    # Ensure that there is at least 1 tile.\n",
    "    num_tiles = max(1, num_tiles)\n",
    "    \n",
    "    # The actual tile-size.\n",
    "    actual_tile_size = math.ceil(num_pixels / num_tiles)\n",
    "    \n",
    "    return actual_tile_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiled_gradient(gradient, image, tile_size=400):\n",
    "    # Allocate an array for the gradient of the entire image.\n",
    "    grad = np.zeros_like(image)\n",
    "\n",
    "    # Number of pixels for the x- and y-axes.\n",
    "    x_max, y_max, _ = image.shape\n",
    "\n",
    "    # Tile-size for the x-axis.\n",
    "    x_tile_size = get_tile_size(num_pixels=x_max, tile_size=tile_size)\n",
    "    # 1/4 of the tile-size.\n",
    "    x_tile_size4 = x_tile_size // 4\n",
    "\n",
    "    # Tile-size for the y-axis.\n",
    "    y_tile_size = get_tile_size(num_pixels=y_max, tile_size=tile_size)\n",
    "    # 1/4 of the tile-size\n",
    "    y_tile_size4 = y_tile_size // 4\n",
    "\n",
    "    # Random start-position for the tiles on the x-axis.\n",
    "    # The random value is between -3/4 and -1/4 of the tile-size.\n",
    "    # This is so the border-tiles are at least 1/4 of the tile-size,\n",
    "    # otherwise the tiles may be too small which creates noisy gradients.\n",
    "    x_start = random.randint(-3*x_tile_size4, -x_tile_size4)\n",
    "\n",
    "    while x_start < x_max:\n",
    "        # End-position for the current tile.\n",
    "        x_end = x_start + x_tile_size\n",
    "        \n",
    "        # Ensure the tile's start- and end-positions are valid.\n",
    "        x_start_lim = max(x_start, 0)\n",
    "        x_end_lim = min(x_end, x_max)\n",
    "\n",
    "        # Random start-position for the tiles on the y-axis.\n",
    "        # The random value is between -3/4 and -1/4 of the tile-size.\n",
    "        y_start = random.randint(-3*y_tile_size4, -y_tile_size4)\n",
    "\n",
    "        while y_start < y_max:\n",
    "            # End-position for the current tile.\n",
    "            y_end = y_start + y_tile_size\n",
    "\n",
    "            # Ensure the tile's start- and end-positions are valid.\n",
    "            y_start_lim = max(y_start, 0)\n",
    "            y_end_lim = min(y_end, y_max)\n",
    "\n",
    "            # Get the image-tile.\n",
    "            img_tile = image[x_start_lim:x_end_lim,\n",
    "                             y_start_lim:y_end_lim, :]\n",
    "\n",
    "            # Create a feed-dict with the image-tile.\n",
    "            feed_dict = model.create_feed_dict(image=img_tile)\n",
    "            \n",
    "            \n",
    "\n",
    "            # Use TensorFlow to calculate the gradient-value.\n",
    "            g = session.run(gradient, feed_dict=feed_dict)\n",
    "\n",
    "            # Normalize the gradient for the tile. This is\n",
    "            # necessary because the tiles may have very different\n",
    "            # values. Normalizing gives a more coherent gradient.\n",
    "            g /= (np.std(g) + 1e-8)\n",
    "\n",
    "            # Store the tile's gradient at the appropriate location.\n",
    "            grad[x_start_lim:x_end_lim,\n",
    "                 y_start_lim:y_end_lim, :] = g\n",
    "            \n",
    "            # Advance the start-position for the y-axis.\n",
    "            y_start = y_end\n",
    "\n",
    "        # Advance the start-position for the x-axis.\n",
    "        x_start = x_end\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_image(layer_tensor, image,\n",
    "                   num_iterations=10, step_size=3.0, tile_size=400,\n",
    "                   show_gradient=False):\n",
    "    \"\"\"\n",
    "    Use gradient ascent to optimize an image so it maximizes the\n",
    "    mean value of the given layer_tensor.\n",
    "\n",
    "    Parameters:\n",
    "    layer_tensor: Reference to a tensor that will be maximized.\n",
    "    image: Input image used as the starting point.\n",
    "    num_iterations: Number of optimization iterations to perform.\n",
    "    step_size: Scale for each step of the gradient ascent.\n",
    "    tile_size: Size of the tiles when calculating the gradient.\n",
    "    show_gradient: Plot the gradient in each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy the image so we don't overwrite the original image.\n",
    "    img = image.copy()\n",
    "\n",
    "    print(\"Processing image: \")\n",
    "\n",
    "    # Use TensorFlow to get the mathematical function for the\n",
    "    # gradient of the given layer-tensor with regard to the\n",
    "    # input image. This may cause TensorFlow to add the same\n",
    "    # math-expressions to the graph each time this function is called.\n",
    "    # It may use a lot of RAM and could be moved outside the function.\n",
    "    gradient = model.get_gradient(layer_tensor)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Calculate the value of the gradient.\n",
    "        # This tells us how to change the image so as to\n",
    "        # maximize the mean of the given layer-tensor.\n",
    "        grad = tiled_gradient(gradient=gradient, image=img)\n",
    "\n",
    "        # Blur the gradient with different amounts and add\n",
    "        # them together. The blur amount is also increased\n",
    "        # during the optimization. This was found to give\n",
    "        # nice, smooth images. You can try and change the formulas.\n",
    "        # The blur-amount is called sigma (0=no blur, 1=low blur, etc.)\n",
    "        # We could call gaussian_filter(grad, sigma=(sigma, sigma, 0.0))\n",
    "        # which would not blur the colour-channel. This tends to\n",
    "        # give psychadelic / pastel colours in the resulting images.\n",
    "        # When the colour-channel is also blurred the colours of the\n",
    "        # input image are mostly retained in the output image.\n",
    "        sigma = (i * 4.0) / num_iterations + 0.5\n",
    "        grad_smooth1 = gaussian_filter(grad, sigma=sigma)\n",
    "        grad_smooth2 = gaussian_filter(grad, sigma=sigma*2)\n",
    "        grad_smooth3 = gaussian_filter(grad, sigma=sigma*0.5)\n",
    "        grad = (grad_smooth1 + grad_smooth2 + grad_smooth3)\n",
    "\n",
    "        # Scale the step-size according to the gradient-values.\n",
    "        # This may not be necessary because the tiled-gradient\n",
    "        # is already normalized.\n",
    "        step_size_scaled = step_size / (np.std(grad) + 1e-8)\n",
    "\n",
    "        # Update the image by following the gradient.\n",
    "        img += grad * step_size_scaled\n",
    "\n",
    "        if show_gradient:\n",
    "            # Print statistics for the gradient.\n",
    "            msg = \"Gradient min: {0:>9.6f}, max: {1:>9.6f}, stepsize: {2:>9.2f}\"\n",
    "            print(msg.format(grad.min(), grad.max(), step_size_scaled))\n",
    "\n",
    "            # Plot the gradient.\n",
    "            plot_gradient(grad)\n",
    "        else:\n",
    "            # Otherwise show a little progress-indicator.\n",
    "            print(\". \", end=\"\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "313600 mixed0\n",
      "layer_cav shape is (?, 1)\n",
      "acts shape is (1, ?)\n",
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n",
      "?\n",
      "352800 mixed1\n",
      "layer_cav shape is (?, 1)\n",
      "acts shape is (1, ?)\n",
      "?\n",
      "352800 mixed2\n",
      "layer_cav shape is (?, 1)\n",
      "acts shape is (1, ?)\n",
      "?\n",
      "221952 mixed3\n",
      "layer_cav shape is (?, 1)\n",
      "acts shape is (1, ?)\n",
      "?\n",
      "221952 mixed4\n",
      "layer_cav shape is (?, 1)\n",
      "acts shape is (1, ?)\n",
      "?\n",
      "221952 mixed5\n",
      "layer_cav shape is (?, 1)\n",
      "acts shape is (1, ?)\n",
      "?\n",
      "221952 mixed6\n",
      "layer_cav shape is (?, 1)\n",
      "acts shape is (1, ?)\n",
      "?\n",
      "221952 mixed7\n",
      "layer_cav shape is (?, 1)\n",
      "acts shape is (1, ?)\n",
      "?\n",
      "81920 mixed8\n",
      "layer_cav shape is (?, 1)\n",
      "acts shape is (1, ?)\n",
      "?\n",
      "131072 mixed9\n",
      "layer_cav shape is (?, 1)\n",
      "acts shape is (1, ?)\n",
      "?\n",
      "131072 mixed10\n",
      "layer_cav shape is (?, 1)\n",
      "acts shape is (1, ?)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cav\n",
    "working_dir = '/Users/tyler/Desktop/dissertation/programming/tcav_on_azure'\n",
    "\n",
    "concept = 'zebra'\n",
    "cav_dict = {}\n",
    "layer_names = ['mixed0','mixed1','mixed2','mixed3','mixed4','mixed5','mixed6','mixed7','mixed8','mixed9','mixed10']\n",
    "#layer_names = ['mixed0']\n",
    "for layer_name in layer_names:\n",
    "    subpath = concept + '-random500_0-' + layer_name\n",
    "    cav_path = 'cav_dir/' + subpath + '-linear-0.1.pkl'\n",
    "    path = os.path.join(working_dir, cav_path)\n",
    "    this_cav = cav.CAV.load_cav(path)\n",
    "    cav_dict[layer_name] = this_cav.cavs[0]\n",
    "    step = 0.01  # Gradient ascent step size\n",
    "num_octave = 5  # Number of scales at which to run gradient ascent\n",
    "octave_scale = 1.4  # Size ratio between scales\n",
    "iterations = 10  # Number of ascent steps per scale\n",
    "max_loss = 100000000000\n",
    "\n",
    "\n",
    "#result_prefix = '/home/tyler/Desktop/tcav_on_azure/results/test'\n",
    "\n",
    "size_dict = {'mixed0': 313600,'mixed1': 352800,'mixed2': 352800,'mixed3': 221952,'mixed4': 221952,'mixed5': 221952,'mixed6': 221952,'mixed7': 221952,'mixed8': 81920,'mixed9': 131072,'mixed10': 131072}\n",
    "\n",
    "settings = {\n",
    "    'features': {\n",
    "        'mixed0': 1,#/313600,\n",
    "        'mixed1': 1,#/352800,\n",
    "        'mixed2': 1,#/352800,\n",
    "        'mixed3': 1,#/221952,\n",
    "        'mixed4': 1,#/221952,\n",
    "        'mixed5': 1,#/221952,\n",
    "        'mixed6': 1,#/221952,\n",
    "        'mixed7': 1,#/221952,\n",
    "        'mixed8': 1,#/81920,\n",
    "        'mixed9': 1,#/131072,\n",
    "        'mixed10': 1#/131072\n",
    "    },}\n",
    "\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "sess = K.get_session()\n",
    "\n",
    "loss_2 = K.variable(0.)\n",
    "for layer_name in settings['features']:\n",
    "    coeff = settings['features'][layer_name]\n",
    "    \n",
    "    assert layer_name in layer_dict.keys(), 'Layer ' + layer_name + ' not found in model.'\n",
    "\n",
    "    coeff = settings['features'][layer_name]\n",
    "    acts = layer_dict[layer_name].output\n",
    "    flat_acts = K.flatten(acts)\n",
    "    \n",
    "    len_of_acts = flat_acts.shape[0]\n",
    "    print(len_of_acts)\n",
    "    \n",
    "    layer_cav = K.variable(cav_dict[layer_name].reshape(-1,1))\n",
    "\n",
    "    n = layer_cav.shape[0]\n",
    "    print(n, layer_name)\n",
    "    n_tensor = K.constant(n.value/1000)\n",
    "    \n",
    "    features_shape = tf.shape(flat_acts)\n",
    "    H = features_shape[0]\n",
    "\n",
    "    layer_cav_slice = K.slice(layer_cav,(0,0),(H,1))\n",
    "\n",
    "    flat_acts_slice = K.reshape(flat_acts, shape=[1,H])\n",
    "    \n",
    "    print('layer_cav shape is ' + str(layer_cav_slice.shape))\n",
    "    print('acts shape is ' + str(flat_acts_slice.shape))\n",
    "    \n",
    "    scaling = K.prod(K.cast(K.shape(acts), 'float32'))\n",
    "    \n",
    "    loss_2 += coeff * K.dot(flat_acts_slice,layer_cav_slice) / scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_optimize(layer_tensor, image,\n",
    "                       num_repeats=4, rescale_factor=0.7, blend=0.2,\n",
    "                       num_iterations=10, step_size=3.0,\n",
    "                       tile_size=400):\n",
    "    \"\"\"\n",
    "    Recursively blur and downscale the input image.\n",
    "    Each downscaled image is run through the optimize_image()\n",
    "    function to amplify the patterns that the Inception model sees.\n",
    "\n",
    "    Parameters:\n",
    "    image: Input image used as the starting point.\n",
    "    rescale_factor: Downscaling factor for the image.\n",
    "    num_repeats: Number of times to downscale the image.\n",
    "    blend: Factor for blending the original and processed images.\n",
    "\n",
    "    Parameters passed to optimize_image():\n",
    "    layer_tensor: Reference to a tensor that will be maximized.\n",
    "    num_iterations: Number of optimization iterations to perform.\n",
    "    step_size: Scale for each step of the gradient ascent.\n",
    "    tile_size: Size of the tiles when calculating the gradient.\n",
    "    \"\"\"\n",
    "\n",
    "    # Do a recursive step?\n",
    "    if num_repeats>0:\n",
    "        # Blur the input image to prevent artifacts when downscaling.\n",
    "        # The blur amount is controlled by sigma. Note that the\n",
    "        # colour-channel is not blurred as it would make the image gray.\n",
    "        sigma = 0.5\n",
    "        img_blur = gaussian_filter(image, sigma=(sigma, sigma, 0.0))\n",
    "\n",
    "        # Downscale the image.\n",
    "        img_downscaled = resize_image(image=img_blur,\n",
    "                                      factor=rescale_factor)\n",
    "            \n",
    "        # Recursive call to this function.\n",
    "        # Subtract one from num_repeats and use the downscaled image.\n",
    "        img_result = recursive_optimize(layer_tensor=layer_tensor,\n",
    "                                        image=img_downscaled,\n",
    "                                        num_repeats=num_repeats-1,\n",
    "                                        rescale_factor=rescale_factor,\n",
    "                                        blend=blend,\n",
    "                                        num_iterations=num_iterations,\n",
    "                                        step_size=step_size,\n",
    "                                        tile_size=tile_size)\n",
    "        \n",
    "        # Upscale the resulting image back to its original size.\n",
    "        img_upscaled = resize_image(image=img_result, size=image.shape)\n",
    "\n",
    "        # Blend the original and processed images.\n",
    "        image = blend * image + (1.0 - blend) * img_upscaled\n",
    "\n",
    "    print(\"Recursive level:\", num_repeats)\n",
    "\n",
    "    # Process the image using the DeepDream algorithm.\n",
    "    img_result = optimize_image(layer_tensor=layer_tensor,\n",
    "                                image=image,\n",
    "                                num_iterations=num_iterations,\n",
    "                                step_size=step_size,\n",
    "                                tile_size=tile_size)\n",
    "    \n",
    "    return img_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from tensorflow import keras\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.inception_v3 import decode_predictions\n",
    "from keras.models import Model, load_model\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import scipy\n",
    "\n",
    "import pickle\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import operator\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import PIL.Image\n",
    "from sklearn.metrics import pairwise\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(0)\n",
    "\n",
    "model = inception_v3.InceptionV3(weights='imagenet',include_top=False)\n",
    "dream = model.input\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Session\n",
    "#session = tf.InteractiveSession(graph=model.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the image is :\n",
      "JPEG (2551, 1431)\n"
     ]
    }
   ],
   "source": [
    "image=load_image(filename='sky.jpg')\n",
    "#plot_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need a reference to the tensor inside the Inception model which we will maximize in the DeepDream algorithm. In this case we select the entire 3rd layer of the Inception model (layer index 2). It has 192 channels and we \n",
    "will try and maximize the average value across all these channels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'layer_tensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2df0bcda34fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlayer_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'layer_tensors'"
     ]
    }
   ],
   "source": [
    "layer_tensor = model.layer_tensors[2]\n",
    "layer_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,\n",
    "                 num_iterations=10, step_size=3.0, rescale_factor=0.7,\n",
    "                 num_repeats=4, blend=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_tensor = model.layer_tensors[6]\n",
    "img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,\n",
    "                 num_iterations=10, step_size=3.0, rescale_factor=0.7,\n",
    "                 num_repeats=4, blend=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_tensor = model.layer_tensors[9][:,:,:,0:2]\n",
    "img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,\n",
    "                 num_iterations=10, step_size=3.0, rescale_factor=0.7,\n",
    "                 num_repeats=4, blend=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_tensor = model.layer_tensors[10]\n",
    "img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,\n",
    "                 num_iterations=10, step_size=3.0, rescale_factor=0.7,\n",
    "                 num_repeats=4, blend=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_tensor = model.layer_tensors[10][:,:,:,0:3]\n",
    "img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,\n",
    "                 num_iterations=10, step_size=3.0, rescale_factor=0.7,\n",
    "                 num_repeats=4, blend=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To save the final Output \n",
    "\n",
    "image_save=save_image(img_result,\"test_output/test_output_11.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# don't forget to have a look over the deep_dream_final_output.html file to see the processed outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
